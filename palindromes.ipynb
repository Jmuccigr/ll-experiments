{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from cltk.corpus.latin import latinlibrary\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from cltk.stem.latin.j_v import JVReplacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CLTK tools\n",
    "\n",
    "word_tokenizer = WordTokenizer('latin')\n",
    "replacer = JVReplacer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of words\n",
    "We can use the Latin Library to generate a list of possible Latin words to match acrostics against by:\n",
    "- Getting the raw text of the Latin Library\n",
    "- Preproccessing the text to remove numbers, punctuation, English words, etc.\n",
    "- Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw text of the Latin Library\n",
    "#\n",
    "# Note that the CLTK Latin Library was updated on 3/25/17\n",
    "# to fix line breaks in some of the hexameter poems included\n",
    "# in this experiment. Please delete and reimport the\n",
    "# CLTK Latin Library corpus to follow along.\n",
    "\n",
    "ll_raw = latinlibrary.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess texts\n",
    "\n",
    "def preprocess(text):    \n",
    "\n",
    "    text = re.sub(r'&aelig;','ae',text)\n",
    "    text = re.sub(r'&AElig;','AE',text)\n",
    "    text = re.sub(r'&oelig;','oe',text)\n",
    "    text = re.sub(r'&OElig;','OE',text)\n",
    "    \n",
    "    text = re.sub('\\x00',' ',text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = replacer.replace(text)\n",
    "    \n",
    "\n",
    "    text= re.sub(r'&lt;','<',text)\n",
    "    text= re.sub(r'&gt;','>',text)    \n",
    "    \n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    remove_list = [r'\\bthe latin library\\b',\n",
    "                   r'\\bthe classics page\\b',\n",
    "                   r'\\bneo-latin\\b', \n",
    "                   r'\\bmedieval latin\\b',\n",
    "                   r'\\bchristian latin\\b',\n",
    "                   r'\\bthe miscellany\\b'\n",
    "                  ]\n",
    "\n",
    "    for pattern in remove_list:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    text = re.sub('[ ]+',' ', text) # Remove double spaces\n",
    "    text = re.sub('\\s+\\n+\\s+','\\n', text) # Remove double lines and trim spaces around new lines\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Latin Library\n",
    "\n",
    "ll_text = preprocess(ll_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the preprocessed text on white space; no need for enclitic splitting, etc. here\n",
    "\n",
    "ll_tokens = ll_text.split()\n",
    "\n",
    "# Remove tokens less than 3 letters long\n",
    "ll_tokens = [token for token in ll_tokens if len(token) > 2]\n",
    "\n",
    "# Remove tokens made up of a single character, e.g. 'aaaa'\n",
    "ll_tokens = [token for token in ll_tokens if token != len(token) * token[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to test for palindromes\n",
    "\n",
    "def is_palindrome(token):\n",
    "    return token == token[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tokens for palindromes\n",
    "\n",
    "palindromes = [token for token in ll_tokens if is_palindrome(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('non', 166078), ('esse', 49426), ('illi', 9922), ('ibi', 7155), ('ecce', 3662), ('tot', 3443), ('sumus', 2678), ('sis', 1526), ('usu', 1472), ('tenet', 1072)]\n"
     ]
    }
   ],
   "source": [
    "# List the 10 most frequent palindromes\n",
    "\n",
    "c = Counter(palindromes)\n",
    "print(c.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of the longest palindromes \n",
    "\n",
    "# Keep only tokens that appear at least 3 times\n",
    "c = Counter(palindromes)\n",
    "palindromes = [k for k, c in c.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "['massinissam', 'simillimis', 'sarabaras', 'muratarum', 'sumeremus', 'siluulis', 'suillius', 'aballaba', 'sumemus', 'sumimus']\n"
     ]
    }
   ],
   "source": [
    "palindromes.sort(key = len, reverse=True)\n",
    "print(len(palindromes))\n",
    "print(palindromes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['massinissam', 'simillimis', 'sarabaras', 'muratarum', 'sumeremus', 'siluulis', 'suillius', 'aballaba', 'sumemus', 'sumimus', 'sububus', 'mutatum', 'tingnit', 'apocopa', 'madidam', 'tereret', 'ccciccc', 'sumamus', 'sinonis', 'matutam', 'merorem', 'erepere', 'nomimon', 'taedeat', 'eregere', 'erexere', 'rotator', 'senones', 'murorum', 'saccas', 'massam', 'iessei', 'murrum', 'mullum', 'soccos', 'mappam', 'iussui', 'siccis', 'mannam', 'mammam', 'messem', 'summus', 'succus', 'terret', 'selles', 'maiiam', 'tinnit', 'marram', 'cilic', 'rotor', 'noson', 'rogor', 'senes', 'sucus', 'sudus', 'soros', 'seces', 'noton', 'aegea', 'sanas', 'temet', 'siuis', 'lunul', 'malam', 'adada', 'inani', 'neten', 'aerea', 'minim', 'agaga', 'robor', 'oeteo', 'mulum', '\\uf8ffnon\\uf8ff', 'tenet', 'surus', 'seses', 'obibo', 'tedet', 'murum', 'eumue', 'susus', 'taxat', 'cabac', 'aziza', 'nomon', 'anona', 'saxas', 'suius', 'sagas', 'etate', 'itati', 'cxxxc', 'siris', 'adeda', 'illli', 'egage', 'ianai', 'eabae', 'tioit', 'sepes', 'inoni', 'solos', 'teget', 'refer', 'reuer', 'amoma', 'silis', 'teret', 'sumus', 'sonos', 'seres', 'tepet', 'sefes', 'iadai', 'ccicc', 'sicis', 'ebibe', 'sacas', 'aenea', 'subus', 'egoge', 'seges', 'essse', 'ababa', 'sitis', 'sinis', 'maiam', 'acuca', 'satas', 'aitia', 'sedes', 'mutum', 'atita', 'simis', 'ogygo', 'neuen', 'aeaea', 'tabat', 'emme', 'ecce', 'iffi', 'amma', 'teet', 'xiix', 'cqqc', 'cxxc', 'urru', 'arra', 'esse', 'appa', 'noon', 'illi', 'siis', 'adda', 'suus', 'oddo', 'alla', 'assa', 'anna', 'otto', 'acca', 'bppb', 'atta', 'elle', 'irri', 'icci', 'abba', 'ollo', 'issi', 'iuui', 'hoh', 'ese', 'nyn', 'tet', 'oto', 'nin', 'ioi', 'uau', 'ete', 'bib', 'ala', 'ydy', 'ded', 'cic', 'ene', 'isi', 'ara', 'coc', 'a˝a', 'nhn', 'oxo', 'aha', 'bab', 'sus', 'fuf', 'nen', 'νον', 'ibi', 'pop', 'mum', 'ihi', 'ouo', 'eue', 'aea', 'cac', 'mam', 'sis', 'nan', 'opo', 'tit', 'scs', 'pap', 'fyf', 'ini', 'ada', 'ede', 'omo', '渀漀渀', 'eie', 'ror', 'sos', 'afa', 'ici', 'asa', 'idi', 'epe', 'aia', 'mem', 'aza', 'gog', 'did', 'kak', 'tot', 'eae', 'lol', 'geg', 'umu', 'ndn', 'non', 'ere', 'bob', 'eme', 'igi', 'ili', 'tat', 'nun', 'ege', 'ono', 'rer', 'iui', 'gcg', 'tut', 'cxc', 'ses', 'νῦν', 'ata', 'ele', 'uou', 'ipi', 'ana', 'olo', 'imi', 'exe', 'aba', 'ama', 'pup', 'aua', 'rar', 'odo', 'iri', 'oro', 'usu', 'uiu', 'sas', 'ixi', 'iei', 'xix', 'aga', 'unu']\n"
     ]
    }
   ],
   "source": [
    "print(palindromes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
