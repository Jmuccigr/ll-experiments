{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from cltk.corpus.latin import latinlibrary\n",
    "#from cltk.tokenize.sentence import TokenizeSentence\n",
    "#from cltk.tokenize.word import WordTokenizer\n",
    "#from cltk.lemmatize.latin.backoff import BackoffLatinLemmatizer\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "#from cltk.utils.file_operations import open_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up training sentences\n",
    "\n",
    "rel_path = os.path.join('~/cltk_data/latin/model/latin_models_cltk/lemmata/backoff')\n",
    "path = os.path.expanduser(rel_path)\n",
    "\n",
    "# Check for presence of latin_pos_lemmatized_sents\n",
    "file = 'latin_pos_lemmatized_sents.pickle'      \n",
    "\n",
    "latin_pos_lemmatized_sents_path = os.path.join(path, file)\n",
    "if os.path.isfile(latin_pos_lemmatized_sents_path):\n",
    "    latin_pos_lemmatized_sents = open_pickle(latin_pos_lemmatized_sents_path)\n",
    "else:\n",
    "    latin_pos_lemmatized_sents = []\n",
    "    print('The file %s is not available in cltk_data' % file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup CLTK tools\n",
    "\n",
    "#word_tokenizer = WordTokenizer('latin')\n",
    "#sent_tokenizer = TokenizeSentence('latin')\n",
    "#lemmatizer = BackoffLatinLemmatizer(latin_pos_lemmatized_sents)\n",
    "replacer = JVReplacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get raw text of the Latin Library\n",
    "\n",
    "ll_raw = latinlibrary.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cltk.corpus.latin import latinlibrary\n",
    "files = latinlibrary.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aeneid_files = [file for file in files if 'vergil/aen' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vergil/aen1.txt', 'vergil/aen10.txt', 'vergil/aen11.txt', 'vergil/aen12.txt', 'vergil/aen2.txt', 'vergil/aen3.txt', 'vergil/aen4.txt', 'vergil/aen5.txt', 'vergil/aen6.txt', 'vergil/aen7.txt', 'vergil/aen8.txt', 'vergil/aen9.txt']\n"
     ]
    }
   ],
   "source": [
    "print(aeneid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aeneid_raw = latinlibrary.raw(aeneid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll_words = latinlibrary.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_list = list(ll_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_words = set(ll_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_words =[word.lower() for word in ll_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess texts\n",
    "def preprocess(text):    \n",
    "\n",
    "    text = re.sub(r'&aelig;','ae',text)\n",
    "    text = re.sub(r'&AElig;','AE',text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = replacer.replace(text)\n",
    "    \n",
    "\n",
    "    text= re.sub(r'&lt;','<',text)\n",
    "    text= re.sub(r'&gt;','>',text)    \n",
    "    \n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    remove_list = [r'\\bthe latin library\\b', r'\\bthe classics page\\b', r'\\bcicero\\s+?$'] \n",
    "    for pattern in remove_list:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    text = re.sub('[ ]+',' ', text) # Remove double spaces\n",
    "    text = re.sub('\\s+\\n+\\s+','\\n', text) # Remove double lines and trim spaces around new lines\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_words_ = \" \".join(ll_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll_words_ = preprocess(ll_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll_words = ll_words_.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aeneid_edit = preprocess(aeneid_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = aeneid_edit.split('\\n')\n",
    "lines = [line for line in lines if line]\n",
    "initials = [line[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    temp = list(zip(*[input_list[i:] for i in range(n)]))\n",
    "    ngrams = [\"\".join(t) for t in temp]\n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_words = list()\n",
    "for i in range(6,8):\n",
    "    temp = find_ngrams(initials, i)\n",
    "    initial_words += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posuit',\n",
       " 'cuppis',\n",
       " 'pinasi',\n",
       " 'calcar',\n",
       " 'concis',\n",
       " 'dantia',\n",
       " 'sagaci',\n",
       " 'cainis',\n",
       " 'sagacis',\n",
       " 'drancae',\n",
       " 'arabic',\n",
       " 'nactas',\n",
       " 'iussae',\n",
       " 'carpas',\n",
       " 'poseae',\n",
       " 'coemat',\n",
       " 'quaene',\n",
       " 'cerata',\n",
       " 'trinae',\n",
       " 'aethei',\n",
       " 'audiant',\n",
       " 'tatiae']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(initial_words) & set(ll_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sixgrams = find_ngrams(initials,6)\n",
    "sevengrams = find_ngrams(initials,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149\n",
      "7656\n",
      "['anchemolum thalamos ausum incestare nouercae ', 'uos etiam gemini rutulis cecidistis in aruis ', 'daucia laride thymberque simillima proles ', 'indiscreta suis gratusque parentibus error ', 'at nunc dura dedit uobis discrimina pallas ', 'nam tibi thymbre caput euandrius abstulit ensis ', 'te decisa suum laride dextera quaerit ']\n",
      "['sed circum late uolitans iam fama per urbes ', 'ausonias tulerat cum laomedontia pubes ', 'gramineo ripae religauit ab aggere classem', 'aeneas primique duces et pulcher iulus ', 'corpora sub ramis deponunt arboris altae ', 'instituuntque dapes et adorea liba per herbam ', 'subiciunt epulis sic iuppiter ipse monebat ']\n"
     ]
    }
   ],
   "source": [
    "print(sevengrams.index('audiant'))\n",
    "print(sevengrams.index('sagacis'))\n",
    "\n",
    "print(lines[1149:1149+7])\n",
    "print(lines[7656:7656+7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_files = [file for file in files if 'ovid/ovid.met' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ovid/ovid.met1.txt', 'ovid/ovid.met10.txt', 'ovid/ovid.met11.txt', 'ovid/ovid.met12.txt', 'ovid/ovid.met13.txt', 'ovid/ovid.met14.txt', 'ovid/ovid.met15.txt', 'ovid/ovid.met2.txt', 'ovid/ovid.met3.txt', 'ovid/ovid.met4.txt', 'ovid/ovid.met5.txt', 'ovid/ovid.met6.txt', 'ovid/ovid.met7.txt', 'ovid/ovid.met8.txt', 'ovid/ovid.met9.txt']\n"
     ]
    }
   ],
   "source": [
    "print(met_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_raw = latinlibrary.raw(met_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_edit = preprocess(met_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_lines = met_edit.split('\\n')\n",
    "met_lines = [line for line in met_lines if line]\n",
    "met_initials = [line[0] for line in met_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_initial_words = list()\n",
    "for i in range(7,8):\n",
    "    temp = find_ngrams(met_initials, i)\n",
    "    met_initial_words += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nestini']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(met_initial_words) & set(ll_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'nestini' in ll_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14080201"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_list.index('nestini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nestini',\n",
       " 'sonant',\n",
       " 'libri',\n",
       " ',',\n",
       " 'a',\n",
       " 'C&aelig',\n",
       " ';',\n",
       " 'culo',\n",
       " ',',\n",
       " 'quem',\n",
       " 'juxta',\n",
       " 'ignes',\n",
       " 'fortuitos',\n",
       " 'invenerunt',\n",
       " ',',\n",
       " 'ut',\n",
       " 'fama',\n",
       " 'est',\n",
       " ',',\n",
       " 'Digitorum']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_list[14080201:14080201+20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
